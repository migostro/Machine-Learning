{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "ep04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "name1 = \"Daniela Gonzalez Favero\" \r\n",
        "name2 = \"Miguel Pereira Ostrowski\"\r\n",
        "\r\n",
        "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\r\n",
        "              \"help on this assignment, and that this work is my own.\\n\"\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\nName: \", name1)\r\n",
        "print(\"\\nHonor pledge: \", honorPledge)\r\n",
        "\r\n",
        "print(\"\\nName: \", name2)\r\n",
        "print(\"\\nHonor pledge: \", honorPledge)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Name:  Daniela Gonzalez Favero\n",
            "\n",
            "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
            "\n",
            "\n",
            "Name:  Miguel Pereira Ostrowski\n",
            "\n",
            "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "daGWjDiHLetV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddbe60e-e84a-44f7-9e94-047ae1ef8849"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAC0460 / MAC5832 (2021)\n",
        "---\n",
        "\n",
        "## EP4\n",
        "\n",
        "### Objectives:\n",
        "The aim of this EP is to\n",
        "- Practice training of linear, neural networks, and SVMs classifiers using the scikit-learn library (https://scikit-learn.org/)\n",
        "- Practice model evaluation, comparison and selection\n",
        "- Produce a summary report on the performed experiments and main findings\n"
      ],
      "metadata": {
        "id": "L5uRbVdWMREt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# All imports\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "\r\n",
        "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": false,
        "id": "YZ7BAOt9Leta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset preparation\r\n",
        "## 1.1. Downloading data\r\n",
        "Reading the MNIST dataset using the `tensorflow.keras` library:"
      ],
      "metadata": {
        "id": "Xd43x36LNHw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "(X_train_ori, y_train_ori), (X_test_ori, y_test_ori) = mnist.load_data()\r\n",
        "\r\n",
        "print(X_train_ori.shape, y_train_ori.shape)\r\n",
        "print(X_test_ori.shape, y_test_ori.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "metadata": {
        "id": "m-Tf8UO4Letb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3fcaa1-31ed-440f-cfcb-da3d213e6277"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "labels = [\"%s\"%i for i in range(10)]\r\n",
        "\r\n",
        "unique, counts = np.unique(y_train_ori, return_counts=True)\r\n",
        "uniquet, countst = np.unique(y_test_ori, return_counts=True)\r\n",
        "\r\n",
        "fig, ax = plt.subplots()\r\n",
        "rects1 = ax.bar(unique - 0.2, counts, 0.25, label='Train')\r\n",
        "rects2 = ax.bar(unique + 0.2, countst, 0.25, label='Test')\r\n",
        "ax.legend()\r\n",
        "ax.set_xticks(unique)\r\n",
        "ax.set_xticklabels(labels)\r\n",
        "\r\n",
        "plt.title('MNIST classes')\r\n",
        "plt.xlabel('Class')\r\n",
        "plt.ylabel('Frequency')\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "ltIuMQZVLetb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8a0d2729-5d3e-4af6-f472-d78545d66e5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize = (9, 6))\r\n",
        "\r\n",
        "for i in range(6):\r\n",
        "    ax[i//3, i%3].imshow(X_train_ori[i], cmap='gray')\r\n",
        "    ax[i//3, i%3].axis('off')\r\n",
        "    ax[i//3, i%3].set_title(\"Class: %d\"%y_train_ori[i])\r\n",
        "    \r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 6 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "d2KnbATeLetc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d1d50c75-b6da-46b5-b45b-f0cc6ad3bdc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preprocessing\n",
        "Reducing the image size:"
      ],
      "metadata": {
        "id": "LHTViEENqTOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "# Reduce the image size to its half \r\n",
        "X_train = np.array([image[::2, 1::2] for image in X_train_ori])\r\n",
        "X_test  = np.array([image[::2, 1::2] for image in X_test_ori])\r\n",
        "\r\n",
        "y_train = y_train_ori\r\n",
        "y_test = y_test_ori\r\n",
        "\r\n",
        "y_train_padrao = y_train"
      ],
      "outputs": [],
      "metadata": {
        "id": "3wn9ExOMLetd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize = (9, 6))\r\n",
        "\r\n",
        "for i in range(6):\r\n",
        "    ax[i//3, i%3].imshow(X_train[i], cmap='gray')\r\n",
        "    ax[i//3, i%3].axis('off')\r\n",
        "    ax[i//3, i%3].set_title(\"Class: %d\"%y_train_ori[i])\r\n",
        "    \r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 6 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "jNtkwQ_KLetd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a6c88510-1efa-4908-a146-ee87eb4f94a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the intensities to the interval $[0, 1]$:"
      ],
      "metadata": {
        "id": "pQhfQxXlp_5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "X_train = (X_train/255.0).astype('float32').reshape((60000,14*14))\r\n",
        "X_test = (X_test/255.0).astype('float32').reshape((10000,14*14))\r\n",
        "\r\n",
        "print(X_train.dtype)\r\n",
        "print(X_test.dtype)\r\n",
        "\r\n",
        "print(\"\\nShape of X_train: \", X_train.shape)\r\n",
        "print(\"Shape of X_test: \", X_test.shape)\r\n",
        "\r\n",
        "print(\"\\nMinimum value in X_train:\", np.amin(X_train))\r\n",
        "print(\"Maximum value in X_train:\", np.amax(X_train))\r\n",
        "\r\n",
        "print(\"\\nMinimum value in X_test:\", np.amin(X_test))\r\n",
        "print(\"Maximum value in X_test:\", np.amax(X_test))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32\n",
            "float32\n",
            "\n",
            "Shape of X_train:  (60000, 196)\n",
            "Shape of X_test:  (10000, 196)\n",
            "\n",
            "Minimum value in X_train: 0.0\n",
            "Maximum value in X_train: 1.0\n",
            "\n",
            "Minimum value in X_test: 0.0\n",
            "Maximum value in X_test: 1.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "w9EhwWosLete",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d93434-3eec-425e-e0de-a12eeaad4d45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Partitioning dataset\n",
        "Partitioning the original training set into 70% training ($D_{train}$) and 30% validation ($D_{val}$) sets, in a stratified way:\n"
      ],
      "metadata": {
        "id": "PAXBYpmSq2os"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "SEED = 512\r\n",
        "FRACTION = 30/100\r\n",
        "D_train, D_val, y_train, y_val = train_test_split(X_train, \r\n",
        "                                                  y_train, \r\n",
        "                                                  test_size=FRACTION, \r\n",
        "                                                  random_state=SEED\r\n",
        "                                                 )\r\n",
        "\r\n",
        "print(D_train.shape)\r\n",
        "print(D_val.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_val.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 196)\n",
            "(18000, 196)\n",
            "(42000,)\n",
            "(18000,)\n"
          ]
        }
      ],
      "metadata": {
        "id": "GAL2P834UEqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6755c165-33e0-484c-99c7-0cc6565239d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training, evaluating and selecting models\n",
        "Now, we will use $D_{train}$ to train and select three models: a logistic regression model, a neural network model, and a SVM model."
      ],
      "metadata": {
        "id": "KAMBy_iANQPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.1. Model selection method\n",
        "\n",
        "\n",
        "To test different values for hyperparameters and choose the most adequate model, we use the `scikit-learn` library's class `GridSearchCV`. Defining some candidates to hyperparameters, the class will print some metrics and show how we should select the models.\n",
        "\n",
        "After that, we use some metrics implemented in `scikit-learn` library in the `model_selection_metrics()` function, to conclude the choices we made."
      ],
      "metadata": {
        "id": "ZjTQR_EsrkVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "def model_selection_metrics(y, y_predict):\r\n",
        "    \"\"\"\r\n",
        "    Computes three different metrics to evaluate model performance: 'Mean \r\n",
        "    squared error', 'Classification report' (several metrics, such as precision,\r\n",
        "    recall, etc) and the 'Confusion matrix'\r\n",
        "    :param y: class labels\r\n",
        "    :type y: np.ndarray(shape=(N, ))\r\n",
        "    :param y_predict: predicted class labels\r\n",
        "    :type y_predict: np.ndarray(shape=(N, ))\r\n",
        "    \"\"\"  \r\n",
        "\r\n",
        "    print()\r\n",
        "    print(\"Mean squared error:\\n\", mean_squared_error(y, y_predict))\r\n",
        "\r\n",
        "    print()\r\n",
        "    print(\"Classification report:\\n\", classification_report(y, y_predict))\r\n",
        "\r\n",
        "    print()\r\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y, y_predict))"
      ],
      "outputs": [],
      "metadata": {
        "id": "tG6ZPY5GpM7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Logistic Regression\n",
        "Firstly, we use the `GridSearchCV` to find the best cadidates to parameters of the Logistic Regression:"
      ],
      "metadata": {
        "id": "If9Wd1DFempX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "tuned_parameters = [{'C':            np.logspace(-3,3,7),\r\n",
        "                     'penalty':      ['l2'],\r\n",
        "                     'solver':       ['newton-cg', 'lbfgs', 'sag'],\r\n",
        "                     'random_state': [SEED],\r\n",
        "                     'max_iter':     [3000]},\r\n",
        "                     {'C':           np.logspace(-3,3,7),\r\n",
        "                     'penalty':      ['l1', 'l2'],\r\n",
        "                     'solver':       ['liblinear'],\r\n",
        "                     'random_state': [SEED],\r\n",
        "                     'max_iter':     [3000]}\r\n",
        "                     ]\r\n",
        "\r\n",
        "scores = ['precision', 'recall']\r\n",
        "\r\n",
        "for score in scores:\r\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\r\n",
        "    print()\r\n",
        "\r\n",
        "    clf = GridSearchCV(\r\n",
        "        LogisticRegression(), tuned_parameters, scoring='%s_macro' % score, n_jobs=-1\r\n",
        "    )\r\n",
        "    clf.fit(D_train, y_train)\r\n",
        "\r\n",
        "    print(\"Best parameters set found on development set:\")\r\n",
        "    print()\r\n",
        "    print(clf.best_params_)\r\n",
        "    print()\r\n",
        "    print(\"Grid scores on development set:\")\r\n",
        "    print()\r\n",
        "    means = clf.cv_results_['mean_test_score']\r\n",
        "    stds = clf.cv_results_['std_test_score']\r\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\r\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\r\n",
        "              % (mean, std * 2, params))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.848 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.848 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.848 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.885 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.885 (+/-0.005) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.885 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.903 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.903 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.903 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.908 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.908 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.908 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.590 (+/-0.017) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.840 (+/-0.006) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.855 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.876 (+/-0.002) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.892 (+/-0.004) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.893 (+/-0.005) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.900 (+/-0.005) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.899 (+/-0.005) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.006) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.843 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.843 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.843 (+/-0.007) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.884 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.884 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.884 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.902 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.902 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.903 (+/-0.008) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.010) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'newton-cg'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'sag'}\n",
            "0.553 (+/-0.005) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.833 (+/-0.006) for {'C': 0.001, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.853 (+/-0.006) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.874 (+/-0.003) for {'C': 0.01, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.892 (+/-0.005) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.893 (+/-0.005) for {'C': 0.1, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.900 (+/-0.005) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.899 (+/-0.006) for {'C': 1.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.900 (+/-0.005) for {'C': 10.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 100.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.006) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l1', 'random_state': 512, 'solver': 'liblinear'}\n",
            "0.901 (+/-0.005) for {'C': 1000.0, 'max_iter': 3000, 'penalty': 'l2', 'random_state': 512, 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "metadata": {
        "id": "vLL6oBMjCExK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258d7753-0a3c-4c1d-83ef-e840787fcde1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we conclude that the best parameters in this model are:\n",
        "```\n",
        "C = 1e-3,\n",
        "penalty = 'l2',\n",
        "solver = 'lbfgs',\n",
        "max_iter: 5000\n",
        "```\n",
        "(The selection of `max_iter` took into account how many iterations were necessary so that the model would converge, and it was adjusted manually)\n",
        "\n",
        "Now, let's use the `scikit-learn` library implementation of Logistic Regression to train the dataset with the chosen parameters:"
      ],
      "metadata": {
        "id": "rJiNM0R7FXm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "# training\r\n",
        "clf = LogisticRegression(random_state=SEED, max_iter=2000).fit(D_train, y_train)\r\n",
        "\r\n",
        "# predicting\r\n",
        "y_predict = clf.predict(D_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "nNslUgI4a8x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing performance metrics such as the *classifier score* and the *model selection method* that we defined previously:"
      ],
      "metadata": {
        "id": "qTjXhyHNudIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "print()\r\n",
        "print(\"Classifier score:\\n\" , clf.score(D_train, y_train))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_train, y_predict)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifier score:\n",
            " 0.916\n",
            "\n",
            "\n",
            "Mean squared error:\n",
            " 1.4490714285714286\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      4142\n",
            "           1       0.94      0.97      0.95      4685\n",
            "           2       0.92      0.89      0.90      4141\n",
            "           3       0.90      0.88      0.89      4325\n",
            "           4       0.91      0.92      0.92      4087\n",
            "           5       0.88      0.87      0.88      3848\n",
            "           6       0.94      0.95      0.95      4194\n",
            "           7       0.93      0.93      0.93      4398\n",
            "           8       0.89      0.87      0.88      4076\n",
            "           9       0.88      0.90      0.89      4104\n",
            "\n",
            "    accuracy                           0.92     42000\n",
            "   macro avg       0.92      0.91      0.91     42000\n",
            "weighted avg       0.92      0.92      0.92     42000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[4003    1   14    8    9   35   30   10   29    3]\n",
            " [   1 4543   24   14    4   19    2   15   55    8]\n",
            " [  21   50 3689   63   52   23   57   64  110   12]\n",
            " [  16   29   96 3823    2  164   16   39   88   52]\n",
            " [   7   24   26    4 3754    7   36   12   28  189]\n",
            " [  41   25   28  139   40 3354   76   16   88   41]\n",
            " [  29   15   31    3   44   46 3999    4   22    1]\n",
            " [  14   30   58   14   48    7    3 4076   10  138]\n",
            " [  25   84   45  121   23  114   34   14 3557   59]\n",
            " [  18   29   15   40  130   35    2  133   28 3674]]\n"
          ]
        }
      ],
      "metadata": {
        "id": "6WYDkbIreEVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Neural Network\n",
        "Now, we use the `GridSearchCV` to find the best candidates to parameters of the Multi-layer Perceptron:"
      ],
      "metadata": {
        "id": "ejvRxUFOkEkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "tuned_parameters = [{'hidden_layer_sizes': np.arange(10, 14),\r\n",
        "                     'activation': ['identity', 'logistic', 'tanh', 'relu'],\r\n",
        "                     'solver':     ['lbfgs', 'sgd', 'adam'],\r\n",
        "                     'alpha':      np.logspace(-4, -3, 2),\r\n",
        "                     'learning_rate_init': np.logspace(-3, -1, 3),\r\n",
        "                     'random_state': [SEED],\r\n",
        "                     'max_iter':     [500]}\r\n",
        "                     ]\r\n",
        "\r\n",
        "scores = ['precision', 'recall']\r\n",
        "\r\n",
        "for score in scores:\r\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\r\n",
        "    print()\r\n",
        "\r\n",
        "    clf = GridSearchCV(\r\n",
        "        MLPClassifier(), tuned_parameters, scoring='%s_macro' % score, n_jobs=-1\r\n",
        "    )\r\n",
        "    clf.fit(D_train, y_train)\r\n",
        "\r\n",
        "    print(\"Best parameters set found on development set:\")\r\n",
        "    print()\r\n",
        "    print(clf.best_params_)\r\n",
        "    print()\r\n",
        "    print(\"Grid scores on development set:\")\r\n",
        "    print()\r\n",
        "    means = clf.cv_results_['mean_test_score']\r\n",
        "    stds = clf.cv_results_['std_test_score']\r\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\r\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\r\n",
        "              % (mean, std * 2, params))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.871 (+/-0.019) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.005) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.871 (+/-0.014) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.011) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.872 (+/-0.012) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.007) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.874 (+/-0.012) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.873 (+/-0.014) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.006) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.875 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.905 (+/-0.007) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.871 (+/-0.012) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.875 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.923 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.921 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.017) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.900 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.928 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.911 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.935 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.911 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.921 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.923 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.923 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.902 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.017) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.900 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.932 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.916 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.933 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.935 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.916 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.915 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.925 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.891 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.915 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.920 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.896 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.933 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.899 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.920 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.902 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.917 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.925 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.892 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.915 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.003) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.922 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.893 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.934 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.898 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.920 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.931 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.903 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.918 (+/-0.013) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.876 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.883 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.934 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.898 (+/-0.027) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.936 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.932 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.895 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.009) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.918 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.900 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.879 (+/-0.024) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.928 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.884 (+/-0.022) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.934 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.900 (+/-0.030) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.931 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.936 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.933 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.897 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.866 (+/-0.023) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.011) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.005) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.866 (+/-0.016) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.007) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.011) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.866 (+/-0.014) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.907 (+/-0.010) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.903 (+/-0.007) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.868 (+/-0.015) for {'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.906 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.868 (+/-0.016) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.903 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.903 (+/-0.006) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.871 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.908 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.904 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.864 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.907 (+/-0.011) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.906 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.903 (+/-0.010) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.907 (+/-0.009) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.905 (+/-0.008) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.870 (+/-0.016) for {'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.922 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.921 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.923 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.900 (+/-0.018) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.900 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.934 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.910 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.935 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.910 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.921 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.923 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.929 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.923 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.899 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.930 (+/-0.004) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.902 (+/-0.017) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.900 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.931 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.915 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.904 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.933 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.935 (+/-0.003) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.935 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.915 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.914 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.925 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.889 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.915 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.919 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.928 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.895 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.933 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.898 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.920 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.916 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.925 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.891 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.915 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.928 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.003) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.922 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.932 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.930 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.892 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.934 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.003) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.927 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.933 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.929 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.896 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.920 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.931 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.931 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.901 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.926 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.918 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.923 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.871 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.925 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.919 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.928 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.880 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.006) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.934 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.895 (+/-0.027) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.002) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.936 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.932 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.891 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.918 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.926 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.917 (+/-0.015) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.899 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.875 (+/-0.027) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 10, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.918 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.922 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.926 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.918 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.931 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.924 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.918 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.927 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.880 (+/-0.020) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 11, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.924 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.930 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.932 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.929 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.922 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.898 (+/-0.032) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 12, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.917 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.931 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.936 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.932 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.01, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n",
            "0.923 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'lbfgs'}\n",
            "0.933 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'sgd'}\n",
            "0.892 (+/-0.016) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 13, 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 512, 'solver': 'adam'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "metadata": {
        "id": "mG6odelaEWP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we conclude that the best parameters in this model are:\n",
        "```\n",
        "\n",
        "max_iter: 500\n",
        "```\n",
        "(The selection of `max_iter` took into account how many iterations were necessary so that the model would converge, and it was adjusted manually. We also observed that too many iterations would lead the model to overfit: it'd have `score=1`)\n",
        "\n",
        "Now, let's use the `scikit-learn` library implementation of the Multi-layer Perceptron to train the dataset with the chosen parameters:"
      ],
      "metadata": {
        "id": "ZKiTKALbHUps"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# training\r\n",
        "nn = MLPClassifier(random_state=SEED, max_iter=500, learning_rate_init=0.01, hidden_layer_sizes=(10, )).fit(D_train, y_train)\r\n",
        "\r\n",
        "# predicting\r\n",
        "y_predict_nn = nn.predict(D_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6AuFqdmObSei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing performance metrics such as the *classifier score* and the *model selection method* that we defined previously:"
      ],
      "metadata": {
        "id": "BhApshb6ww1B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "print()\r\n",
        "print(\"Classifier score:\\n\" , nn.score(D_train, y_train))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_train, y_predict_nn)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifier score:\n",
            " 0.9340238095238095\n",
            "\n",
            "\n",
            "Mean squared error:\n",
            " 1.1034761904761905\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      4142\n",
            "           1       0.96      0.97      0.97      4685\n",
            "           2       0.93      0.95      0.94      4141\n",
            "           3       0.96      0.86      0.91      4325\n",
            "           4       0.91      0.93      0.92      4087\n",
            "           5       0.91      0.92      0.91      3848\n",
            "           6       0.96      0.96      0.96      4194\n",
            "           7       0.94      0.94      0.94      4398\n",
            "           8       0.94      0.90      0.92      4076\n",
            "           9       0.86      0.94      0.90      4104\n",
            "\n",
            "    accuracy                           0.93     42000\n",
            "   macro avg       0.93      0.93      0.93     42000\n",
            "weighted avg       0.94      0.93      0.93     42000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[4023    1   16    2   14   15   32   14   14   11]\n",
            " [   1 4549   29   13    6   16    5   12   35   19]\n",
            " [  21   12 3931   14   47    6   13   52   24   21]\n",
            " [   7   15  161 3720    7  190    5   60   75   85]\n",
            " [   6    6   22    1 3795    6   28   13    8  202]\n",
            " [  23   15   13   41   51 3543   58   23   42   39]\n",
            " [  29   17    8    0   50   48 4026    0   12    4]\n",
            " [   6   32   30   10   46    9    2 4149    4  110]\n",
            " [  14   67   33   61   36   55   24   14 3650  122]\n",
            " [  13    7    6   18  126   15    1   57   18 3843]]\n"
          ]
        }
      ],
      "metadata": {
        "id": "NnlZ0DcCbfpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. SVM\n",
        "Initially, we had to choose between the several SVM implementation in the library. We began with a *Radial Basis Function (RBF)* kernel (using the `sklearn.svm.SVC` class) and, although it classified very well, the program took too long to finish compared to the previous methods, and it didn't compensate.\n",
        "\n",
        "Therefore, let's use the `GridSearchCV` to find the best candidates to parameters of a Linear Support Vector Machine:\n"
      ],
      "metadata": {
        "id": "KYJvUhfYmf_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "tuned_parameters = [{'penalty':      ['l2'],\r\n",
        "                     'dual':         [False],\r\n",
        "                     'loss' :        ['hinge', 'squared_hinge'],\r\n",
        "                     'C':            [1, 10, 100, 1000],\r\n",
        "                     'tol':          [1e-3, 1e-4],\r\n",
        "                     'random_state': [SEED],\r\n",
        "                     'max_iter':     [5000]}]\r\n",
        "\r\n",
        "scores = ['precision', 'recall']\r\n",
        "\r\n",
        "for score in scores:\r\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\r\n",
        "    print()\r\n",
        "\r\n",
        "    clf = GridSearchCV(\r\n",
        "        LinearSVC(), tuned_parameters, scoring='%s_macro' % score, n_jobs=-1\r\n",
        "    )\r\n",
        "    clf.fit(D_train, y_train)\r\n",
        "\r\n",
        "    print(\"Best parameters set found on development set:\")\r\n",
        "    print()\r\n",
        "    print(clf.best_params_)\r\n",
        "    print()\r\n",
        "    print(\"Grid scores on development set:\")\r\n",
        "    print()\r\n",
        "    means = clf.cv_results_['mean_test_score']\r\n",
        "    stds = clf.cv_results_['std_test_score']\r\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\r\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\r\n",
        "              % (mean, std * 2, params))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 234, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 974, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"C:\\Users\\Miguel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 830, in _get_liblinear_solver_type\n",
            "    raise ValueError('Unsupported set of arguments: %s, '\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5864/1721394921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%s_macro'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[0;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "id": "AIomWoMNSthl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we conclude that the best parameters in this model are:\n",
        "```\n",
        "C = 10,\n",
        "penalty = 'l2',\n",
        "loss = 'squared_hinge',\n",
        "dual = [False],\n",
        "tol = 1e-3,\n",
        "max_iter: 5000\n",
        "```\n",
        "(The selection of `max_iter` took into account how many iterations were necessary so that the model would converge, and it was adjusted manually)\n",
        "\n",
        "Using the `scikit-learn` library implementation of a Linear Support Vector Machine to train the dataset with the chosen parameters:"
      ],
      "metadata": {
        "id": "0A5aFpVQH0jx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# training\r\n",
        "svm_clf = LinearSVC(random_state=SEED, max_iter=5000).fit(D_train, y_train)\r\n",
        "\r\n",
        "# predicting\r\n",
        "y_predict_svm = svm_clf.predict(D_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7yQkJwCHivG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing performance metrics such as the *classifier score* and the *model selection method* that we defined previously:"
      ],
      "metadata": {
        "id": "P2kLPgT_14e-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print()\r\n",
        "print(\"Classifier score:\\n\" , svm_clf.score(D_train, y_train))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_train, y_predict_svm)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lhwy3-xQjZgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Choosing a final model\n",
        "Now, evaluating – on the validation set ($D_{val}$) – the three models selected in the previous step.  \n",
        " Let's compare the performance computed with respect to ($D_{val}$) with the ones obtained in the previous step (in $D_{train}$):"
      ],
      "metadata": {
        "id": "OK8O7ANFNUiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Validating the logistic regression model"
      ],
      "metadata": {
        "id": "QGY-7Xbd5BKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# predicting\r\n",
        "y_predict_val = clf.predict(D_val)\r\n",
        "\r\n",
        "# estimating metrics\r\n",
        "print()\r\n",
        "print('Classifier score:\\n', clf.score(D_val, y_val))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_val, y_predict_val)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8-t6LZk_nJSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Validating the multi-layer perceptron model"
      ],
      "metadata": {
        "id": "QIxm7yCN5Kj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# predicting\r\n",
        "y_predict_nn_val = nn.predict(D_val)\r\n",
        "\r\n",
        "# estimating metrics\r\n",
        "print()\r\n",
        "print('Classifier score:\\n', nn.score(D_val, y_val))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_val, y_predict_nn_val)"
      ],
      "outputs": [],
      "metadata": {
        "id": "LY9N7Wmc0alV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Validating the linear SVM model"
      ],
      "metadata": {
        "id": "BcpCRycp5RY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# predicting\r\n",
        "y_predict_svm_val = svm_clf.predict(D_val)\r\n",
        "\r\n",
        "# estimating metrics\r\n",
        "print()\r\n",
        "print('Classifier score:\\n', svm_clf.score(D_val, y_val))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_val, y_predict_svm_val)"
      ],
      "outputs": [],
      "metadata": {
        "id": "BzpmHayZ0bLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Comparing the three models\n",
        "The computed metrics on the validation set can be more clearly compared through the table:\n",
        "\n",
        "|                   | Score | MSE  | Accuracy |  \n",
        "|:-----------------:|:-----:|:----:|:--------:|  \n",
        "| Linear Regression | 0.91  | 1.56 | 0.91     |\n",
        "| Neural Networks   | 0.92  | 1.35 | 0.92     |\n",
        "| Linear SVM        | 0.90  | 1.74 | 0.90     |\n",
        "\n",
        "Thus, we can conclude that the **Neural Networks** have the highest score and accuracy, and also the lowest error; so that's our final chosen model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PT13k20T44Y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Error estimation\n",
        "Computing an estimate of the final model expected performance ($E_{out}$ and other metrics/analysis)."
      ],
      "metadata": {
        "id": "bveTKPbjNYUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Estimating metrics over $D_{test}$\n",
        "Printing $E_{out}$ and other metrics/analysis, using neural networks:"
      ],
      "metadata": {
        "id": "oHyBxVmu9OSv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# predicting\r\n",
        "y_predict_nn_test = nn.predict(X_test)\r\n",
        "\r\n",
        "# estimating metrics\r\n",
        "print()\r\n",
        "print('Classifier score:\\n', nn.score(X_test, y_test))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_test, y_predict_nn_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "I6VsfKGs2Uoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's do a **Cross validation**, comparing the error outputs of training versus testing:\n",
        "\n",
        "|            | MSE  |\n",
        "|:----------:|:----:| \n",
        "| Training   | 1.20 | \n",
        "| Validating | 1.35 | \n",
        "| Testing    | 1.26 |\n",
        "\n",
        "<!-- TODO: COMENTAR SOBRE A CROSS VALIDATION -->"
      ],
      "metadata": {
        "id": "dKeJbvcZ-hHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Retraining the selected method on $D_{train} \\cup D_{val}$\n",
        "Now, let's retrain the neural network on $D_{train} \\cup D_{val}$ and verify if there is any significant\n",
        "difference:"
      ],
      "metadata": {
        "id": "0AnyudlQ-vsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# training\r\n",
        "nn2 = MLPClassifier(random_state=SEED, max_iter=500, learning_rate_init=0.01, hidden_layer_sizes=(10, )).fit(X_train, y_train_padrao)\r\n",
        "\r\n",
        "# predicting\r\n",
        "y_predict_nn2 = nn2.predict(X_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2VjPN5hZ9Brz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing performance metrics such as the *classifier score* and the *model selection method* that we defined previously:"
      ],
      "metadata": {
        "id": "vZkMgfMcAHGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# estimating metrics\r\n",
        "print()\r\n",
        "print('Classifier score:\\n', nn2.score(X_train, y_train_padrao))\r\n",
        "\r\n",
        "print()\r\n",
        "model_selection_metrics(y_train_padrao, y_predict_nn2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "AppPCOLM-d3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing an estimate of the final model expected performance ($E_{out}$ and other metrics/analysis):"
      ],
      "metadata": {
        "id": "vScKJBpnAfeX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_predict_nn2_test = nn2.predict(X_test)\r\n",
        "print('Classifier score:\\n', nn2.score(X_test, y_test))\r\n",
        "\r\n",
        "model_selection_metrics(y_test, y_predict_nn2_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VNHrWwb7-SlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance metrics computed on $D_{train} \\cup D_{val}$ still hold the high score and accuracy, and also the low error. That means that the output error $E_{out}$ is low, and our choices of a model keep showing to be a precise fit for the dataset."
      ],
      "metadata": {
        "id": "W5r3e5HuCtPR"
      }
    }
  ]
}